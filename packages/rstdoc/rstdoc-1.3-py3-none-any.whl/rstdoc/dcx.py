#!/usr/bin/env python
#encoding: utf-8 

##lns=open(__file__).readlines()
##list(gen_head(lns))
#def gen_head(lns,**kw):
#    b,e = list(rindices('^"""',lns))[:2]
#    return lns[b+1:e]
#def gen_head
##list(gen_api(lns))
#def gen_api(lns,**kw):
#    yield from doc_parts(lns,signature='py',prefix='dcx.')
#def gen_api

"""
.. _`rstdcx`:

rstdcx
======

Support script to create documentation (PDF, HTML, DOCX)
from restructuredText (RST). 

- For HTML ``Sphinx`` is used.
- For PDF ``Pandoc`` is used (``Sphinx`` would work, too).
- For DOCX ``Pandoc`` is used, therefore *no Sphinx extension*.

``rstdcx``, or ``dcx.py`` creates

- processes ``gen`` files (see examples produced by --init)

- _links_pdf.rst _links_docx.rst _links_sphinx.rst

- .tags

See example at the end of ``dcx.py``.

Usage
-----

If installed, ``./dcx.py`` in the following examples can be replaced by ``rstdcx``.

- Initialize example tree::

  $ ./dcx.py --init tmp

- Only create .tags and _links_xxx.rst::

  $ cd tmp/src/doc
  $ ./dcx.py

- Create the docs (and .tags and _links_xxx.rst) with make::

  $ make html
  $ make docx
  $ make pdf

- Create the docs (and .tags and _links_xxx.rst) with waf:

  Instead of using ``make`` one can load this file in `waf <https://github.com/waf-project/waf>`__.
  ``waf`` also considers all recursively included files,
  such that a change in any of them results in a rebuild of the documentation. 
  ``bld`` will be able to render `.stpl` extension.
  It uses `SimpleTemplate <https://bottlepy.org/docs/dev/stpl.html#simpletemplate-syntax>`__.
  To test this, you will need to copy ``waf`` and ``waf.bat``, created by ``python waf-light``, 
  into ``src`` generated by ``--init``. Then rename e.g. ``ra.rest`` to ``ra.rest.stpl`` and do::

    $ waf configure
    $ waf --docs html,pdf,docx

  With ``waf`` also ``.tikz`` files are converted to ``.png`` and placed into ``./_images`` or ``../_images``.
  This needs LaTex and `sphinxcontrib-tikz <https://bitbucket.org/philexander/tikz>`__.

Conventions
-----------

- Main files have ``.rest`` extension, converted by Sphinx and Pandoc.
- Included files have extension ``.rst`` ignored by Sphinx (see conf.py).
- ``.. _`id`:`` are targets.
- References use replacement `substitutions`_: ``|id|``.
- ``x.rest.stpl`` and ``y.rst.stpl`` must be rendered separately before ``.. include: y.rst``.
- ``.rst.tpl`` is included 

  - with ``%include('some.rst.tpl',param="test")`` with optional parameters
  - with ``%globals().update(include('utility.rst.tpl'))`` if it contains only definitions

  Template lookup is done in in ``.`` and ``..``.

  *Targets* must not be generated, but explicit and same in ``.rest.stpl`` and rendered ``.rest``.
  If one wants to generate them, then this must happen in a previous step, e.g. with ``gen``.

See the example created with ``--init`` at the end of this file and the sources of the documentation of 
`rstdoc <https://github.com/rpuntaie/rstdoc>`__.

.. _`substitutions`: http://docutils.sourceforge.net/docs/ref/rst/directives.html#replacement-text

"""


'''
API
---

.. code-block:: py

   import rstdoc.dcx as dcx


The functions in ``dcx.py`` are available to the ``gen_xxx(lns,**kw)`` functions (|dhy|).

'''

import sys
import os
import re
import subprocess
from pathlib import Path
from urllib import request
import string
from functools import lru_cache
from collections import OrderedDict,defaultdict
from itertools import chain, tee
from types import GeneratorType

try:
    import pyfca
except:
    pyfca = None

Tee = tee([], 1)[0].__class__
def memoized(f):
    cache={}
    def ret(*args):
        if args not in cache:
            cache[args]=f(*args)
        if isinstance(cache[args], (GeneratorType, Tee)):
            cache[args], r = tee(cache[args])
            return r
        return cache[args]
    return ret

verbose = False
_stpl = '.stpl'
is_rest = lambda x: x.endswith('.rest') or x.endswith('.rest'+_stpl)
is_rst = lambda x: x.endswith('.rst') or x.endswith('.rst'+_stpl) or x.endswith('.rst.tpl')


rextgt = re.compile(r'(?:^|^[^\.\%\w]*\s|^\s*\(?\w+[\)\.]\s)\.\. _`?(\w[^:`]*)`?:\s*$')
rextitle = re.compile(r'^([!"#$%&\'()*+,\-./:;<=>?@[\]^_`{|}~])\1+$')
rexitem = re.compile(r'^\s*:?(\w[^:]*):\s*.*$')
rexoneword = re.compile(r'^\s*(\w+)\s*$')
rexname = re.compile(r'^\s*:name:\s*(\w.*)*$')
rexlinksto = re.compile(r'[^`]?\|(\w+)\|[^`]?')
reximg = re.compile(r'image:: ((?:\.|/|\\|\w).*)')
#list(rexlinksto.findall('|xx| A |lnk| here |gos|'))
#rextgt.search('.. _`_t11`:').group(1)
#rextgt.search('  .. _`_t11`:').group(1)
#rextgt.search('#) .. _`_t11`:').group(1)
#rextgt.search('- .. _`_t11`:').group(1)
#rextgt.search('2) .. _`_t11`:').group(1)
#rextgt.search('2. .. _`_t11`:').group(1)
#rextgt.search('(a) .. _`_t11`:').group(1)
#rextgt.search('| .. _`_t11`:').group(1)
#rextgt.search('  * - .. _`_t11`:').group(1)
#rextgt.search('x  .. _`_t11`:').group(1)#nok
#rextgt.search('.. .. _`_t11`:').group(1)#nok
#rextgt.search('%# .. _`_t11`:').group(1)#nok
#rexitem.match(':``t11``:').group(1)#nok
#rexitem.match(':t11:').group(1)#ok
#reximg.search('.. image:: ..\img.png').group(1)
#reximg.search(r'.. |c:\x y\im.jpg| image:: /tmp/img.png').group(1)
#reximg.search(r'.. image:: c:\tmp\img.png').group(1)
#reximg.search(r'.. image:: \\public\img.png').group(1)
rerstinclude = re.compile(r'\.\. include::\s*([\./\w\\].*)')
restplinclude = re.compile(r'''%\s*include\s*\(\s*["']([^'"]+)['"].*\)\s*''')
#rerstinclude.split('.. include:: test.rst')
#rerstinclude.split('.. include:: ../test.rst')
#rerstinclude.split('  .. include:: ../test.rst')
#restplinclude.split('%include("test.rst.stpl",v="aparam")')
#restplinclude.split('%include("../test.rst.stpl",v="aparam")')
#restplinclude.split('% include(  "../test.rst.stpl",v="aparam")')


nj = lambda *x:os.path.normpath(os.path.join(*x))

trace_file_name = '_trace' #used for _trace.rst and _trace.svg
trace_target= 'index'

def rindices(
    r #regular expression string or compiled
    ,lns #lines
    ):
    '''
    Return the indices matching the regular expression ``r``.

    ::

      >>> lns=['a','ab','b','aa']
      >>> [lns[i] for i in rindices(r'^a\w*',lns)]==['a', 'ab', 'aa']
      True

    '''

    if isinstance(r,str):
        r = re.compile(r)
    for i,ln in enumerate(lns):
        if r.search(ln):
            yield i 

def rlines(
    r #regular expression string or compiled
    ,lns #lines
    ):
    '''
    Return the lines matched by ``r``.
    '''

    return [lns[i] for i in rindices(r,lns)]

def intervals(
    nms #list of indices
    ):
    """
    Return intervals between numbers.

    ::

      >>> intervals([1,2,3])==[(1, 2), (2, 3)]
      True

    """
    return list(zip(nms[:],nms[1:]))

def in2s(
    nms #list of indices
    ):
    """
    Convert the list into a list of couples of two elements.
    
    ::

      >>> in2s([1,2,3,4])==[(1, 2), (3, 4)]
      True

    """
    return list(zip(nms[::2],nms[1::2]))


#re.search(reid,'OpenDevices = None').groups()
#re.search(reid,'def OpenDevices(None)').groups()
#re.search(reid,'class OpenDevices:').groups()
#re.search(reid,'    def __init__(a,b):').groups()

#re.search(relim,"  '''prefix. ").groups()
#re.search(relim,"  '''").groups()

def doc_parts(
    lns #list of lines
    ,relim=r"^\s*'''([\w.:]*)\s*\n*$" #regular expression marking lines enclosing the documentation. The group is a prefix.
    ,reid=r"\s(\w+)[(:]|(\w+)\s\=" #extract id from preceding or succeeding non-empty lines
    ,reindent=r'[^#/\s]' #determines start of text
    ,signature=None #if signature language is given the preceding or succeeding lines will be included
    ,prefix='' #prefix to make id unique, e.g. module name. Include the dot.
    ):
    '''
    ``doc_parts()`` yields doc parts delimeted by ``relim`` regular expression
    possibly with id, if ``reid`` matches 

    If start and stop differ use regulare expression ``|`` in ``relim``.

    ::

      >>> list(doc_parts(open(__file__).readlines(),signature='py'))

    - There is no empty line between doc string and preceding code lines that should be included.
    - There is no empty line between doc string and succeeding code lines that should be included.
    - Included code lines end with an empty line.

    In case of ``__init__()`` the ID can come from the ``class`` line
    and the included lines can be those of ``__init__()``,
    if there is no empty line between the doc string and ``class`` above as well as ``_init__()`` below.

    If the included code comes only from one side of the doc string, have an empty line at the other side.

    Immediately after the initial doc string marker there can be a prefix, e.g. ``classname.``.

    '''

    rlim = re.compile(relim)
    rid = re.compile(reid)
    rindent = re.compile(reindent)
    def foundid(lnsi):
        if not lnsi.strip():#empty
            return False
        id = rid.search(lnsi)
        if id and id.groups():
            ids = [x for x in id.groups() if x is not None]
            if len(ids) > 0:
                return ids[0]
    ids = []
    def checkid(rng):
        i = None
        for i in rng:
            testid = foundid(lns[i])
            if testid is False:
                break
            elif not ids and isinstance(testid,str):
                ids.append(testid)
        return i
    for a,b in in2s(list(rindices(rlim,lns))):
        try:
            thisprefix = rlim.search(lns[a]).groups()[0]
        except:
            thisprefix = ''
        ids.clear()
        i = checkid(range(a-1,0,-1))
        j = checkid(range(b+1,len(lns)))
        if ids:
            yield
            yield '.. _`'+prefix+thisprefix+ids[0]+'`:\n'
            yield
            yield ':'+prefix+thisprefix+ids[0]+':\n'
            yield
        if signature:
            if i is not None and i < a and i > 0:
                if not lns[i].strip():#empty
                    i = i+1
                if i < a:
                    yield '.. code-block:: '+signature+'\n'
                    yield
                    yield from ('   '+x for x in lns[i:a])
                    yield
            if j is not None and j > b+1 and j < len(lns):
                if not lns[j].strip():#empty
                    j = j-1
                if j > b:
                    yield '.. code-block:: '+signature+'\n'
                    yield
                    yield from ('   '+x for x in lns[b+1:j+1])
                    yield
        indent = 0
        for ln in lns[a+1:b]:
            lnst = rindent.search(ln)
            if lnst and lnst.span():
                indent = lnst.span()[0]
                break;
        yield from (x[indent:] for x in lns[a+1:b])

@lru_cache()
def _read_lines(fn):
    lns = []
    with open(fn,'r',encoding='utf-8') as f:
        lns = f.readlines()
    return lns

def _read_stpl_lines_it(fn):
    """
    This flattens the .stpl includes to have all targets align to those in the .rest file.
    Targets must not be *explicit* in all .stpl. They must not be created by stpl.
    This is needed to make the .tags jump to the original and not the generated file.
    """
    #def stpl(file_or_string,**kw):
    #    from bottle import template
    #    return template(file_or_string
    #            ,template_lookup = [os.getcwd(),os.path.dirname(os.getcwd())]
    #            ,**kw
    #            ) 
    #fil=list(_read_stpl_lines('main.rest.stpl'))
    #lns=stpl('main.rest.stpl')
    flns = []
    if os.path.exists(fn):
        flns = _read_lines(fn)
    else:
        parnt = os.path.normpath(os.path.join(os.path.dirname(fn),'..',fn))
        if os.path.exists(parnt):
            flns = _read_lines(parnt)
    for i,ln in enumerate(flns):
        m = restplinclude.match(ln)
        if m: 
            yield from _read_stpl_lines(os.path.join(os.path.dirname(fn),m.group(1)))
        else:
            yield fn,i,ln

@lru_cache()
def _read_stpl_lines(fn):
    return list(_read_stpl_lines_it(fn))

@memoized
def rstincluded(
    fn #file name without path
    ,paths=() #paths where to look for fn
    ,withimg=False #also yield image files, not just other rst files
    ):
    '''
    Yield the files recursively included from an RST file.
    '''

    for p in paths:
        nfn = os.path.normpath(os.path.join(p,fn))
        if os.path.exists(nfn+_stpl): #first, because original
            nfn = nfn+_stpl
            yield fn+_stpl
            break
        elif os.path.exists(nfn): #while this might be generated
            yield fn
            break
    else:
        nfn = fn
        yield fn
    lns = _read_lines(nfn)
    toctree = False
    if lns:
        for e in lns:
            if toctree:
                toctreedone = False
                if e.startswith(' '):
                    fl=e.strip()
                    if fl.endswith('.rest') and os.path.exists(fl):
                        toctreedone = True
                        yield from rstincluded(fl,paths)
                    continue
                elif toctreedone:
                    toctree = False
            if e.startswith('.. toctree::'):
                toctree = True
            elif e.startswith('.. '):
                #e = '.. include:: some.rst'
                #e = '.. include:: ../some.rst'
                #e = '.. image:: some.png'
                #e = '.. figure:: some.png'
                #e = '.. |x y| image:: some.png'
                try:
                    f,t,_ = rerstinclude.split(e)
                    nf = not f and t
                    if nf and not nf.startswith('_links_'):
                        yield from rstincluded(nf.strip(),paths)
                except:
                    if withimg:
                        m = reximg.search(e)
                        if m:
                            yield m.group(1)
            elif restplinclude.match(e): 
                #e="%include('some.rst.tpl',v='param')" #no '../some.rst.tpl': current and parent folder are automatically searched
                f,t,_=restplinclude.split(e)
                nf = not f and t
                if nf:
                    try:
                        if not os.path.exists(nf):
                            nf = os.path.join('..',nf)
                        yield from rstincluded(nf.strip(),paths)
                    except:
                        pass

def fldrincluded(
        directory='.'
        ,exclude_paths_substrings = ['_links_','index.rest',trace_file_name]
        ):
    ''' 
    Yield a list of .rest files for each directory below ``directory``.
    The list also includes all files recursively included via these `.rest` files,
    excluding those that contain ``exclude_paths_substrings``
    '''

    global trace_target
    sofar = []
    for p,ds,fs in os.walk(directory):
        for f in reversed(sorted(fs)):
            if is_rest(f):
                pf=nj(p,f)
                if any([x in pf for x in exclude_paths_substrings]):
                    continue
                if pf in sofar:
                    continue
                sofar.append(pf)
                if pf.endswith(_stpl):
                    sofar.append(pf[:-len(_stpl)])
                res = []
                for ff in rstincluded(f,(p,)):
                    if trace_file_name in ff:
                        trace_target = os.path.splitext(f)[0]
                    if any([x in ff for x in exclude_paths_substrings]):
                        continue
                    pth=nj(p,ff)
                    if any([x in pth for x in exclude_paths_substrings]):
                        continue
                    res.append(pth.replace("\\","/"))
                yield res

def links(lns):
    for i,ln in enumerate(lns):
        mo = rexlinksto.findall(ln)
        for g in mo:
            yield i,g

def pair(a,b,cmp):
    """ pair two sorted lists
    b must be longer than a
    >>> a=[1,2,4,7]
    ... b=[1,2,3,4,5,6,7]
    ... cmp = lambda x,y: x==y
    ... list(pair(a,b,cmp))
    [(1, 1), (2, 2), (None, 3), (4, 4), (None, 5), (None, 6), (7, 7)]
    """
    for i,(aa,bb) in enumerate(zip(a,b)):
        if not cmp(aa,bb):
            break
        yield aa,bb
    alen = len(a)
    tlen = max(alen,len(b))
    d = 0
    for j in range(i,alen):
        for dd in range(tlen-j-d):
            bb = b[j+d+dd]
            if not cmp(a[j],bb):
                yield None,bb
            else:
                yield a[j],bb
                d = d+dd
                break
        else:
            return

class RstDocError(Exception):
    pass

g_counters=defaultdict(dict)

def make_tgts(
    lns  #lines of the document
    ,doc #doc .rest file name
    ,fil=None #stpl lines
    ):
    '''
    Yields line index, target and link name of ``lns`` of a RST file (lns)
    and zip to flattened stpl for .tags.
    '''

    docprefix = ' '
    if doc not in g_counters:
        g_counters[doc] = {".. figure":1,".. math":1,".. table":1,".. code":1} #=list-table,code-block
    counters=g_counters[doc]
    itgts = list(rindices(rextgt,lns))
    if fil:
        lns1 = [x[2] for x in fil]
        itgts1 = list(rindices(rextgt,lns1))
    else:
        lns1 = lns
        itgts1 = itgts
    if len(itgts)<len(itgts1):
        paired_itgts_itgts1 = pair(itgts,itgts1,lambda x,y:lns[x]==lns1[y])
    elif len(itgts)>len(itgts1):
        raise RstDocError(".rest has more targets than .stpl. Targets cannot be generated.")
    else:
        paired_itgts_itgts1 = zip(itgts,itgts1)
    lenlns = len(lns)
    lenlns1 = len(lns1)
    def is_literal(ii,iis,spc):
        for iprev in range(ii-1,0,-1):
           prev = iis[iprev]
           if prev:
               newspc,_ = next((ich,ch) for ich,ch in enumerate(prev) if ch!=' ' and ch!='\t')
               if newspc<spc:
                   prev = prev.strip()
                   if prev:
                       if not prev.startswith('.. ') and prev.endswith('::'):
                           return True
                       return False
    for i,i1 in paired_itgts_itgts1:
        ii,iis,iilen = (i,lns,lenlns) if i else (i1,lns1,lenlns1)
        cur = iis[ii]
        tgt = rextgt.search(cur).group(1)
        #cur = ' .. _`x`:'
        try:#skip literal blocks
            spc = re.search('\w',cur).span()[0]-3
            if spc>0 and is_literal(ii,iis,spc):
                continue
        except:
            pass
        lnkname = tgt
        for j in range(ii+2,ii+8):
            #j=i+2
            if j > iilen-1:
                break
            lnj = iis[j]
            if rextitle.match(lnj):
                lnkname=iis[j-1].strip()
                if not lnkname:
                    lnkname=iis[j+1].strip()
                break
            #j,iis=1,".. figure::\n  :name: lnkname".splitlines();lnj=iis[j]
            #j,iis=1,".. figure::\n  :name:".splitlines();lnj=iis[j]
            #j,iis=1,".. math::\n  :name: lnkname".splitlines();lnj=iis[j]
            itm = rexname.match(lnj)
            if itm:
                lnkname, = itm.groups()
                lnj1 = iis[j-1].split('::')[0].replace('list-table','table').replace('code-block','code').strip()
                if not lnkname and lnj1 in counters:
                    lnkname = lnj1[3].upper()+lnj1[4:]+docprefix+str(counters[lnj1])
                    counters[lnj1]+=1
                    break
                elif lnkname:
                    lnkname = lnkname.strip()
                    break
            #lnj=":lnkname: words"
            itm = rexitem.match(lnj)
            if itm:
                lnkname, = itm.groups()
                break
            itm = rexoneword.match(lnj)
            if itm:
                lnkname, = itm.groups()
                break
            lnkname = tgt
        yield (i,fil[i1][:2] if fil else (doc,ii)), tgt, lnkname

def gen(
    source #either a list of lines of a path to the source code
    ,target=None #either save to this file or return the generated documentation
    ,fun=None #use ``#gen_<fun>(lns,**kw):`` to extract the documtenation
    ,**kw #kw arguments to the gen_<fun>() function
    ):
    ''' 
    Take the ``gen_[fun]`` functions enclosed by ``#def gen_[fun](lns,**kw)`` to create a new file.

    Example::

        >>> source=[i+'\\n' for i in """
        ...        #def gen(lns,**kw):
        ...        #  return [l.split('#@')[1] for l in rlines('^\s*#@',lns)]
        ...        #def gen
        ...        #@some lines
        ...        #@to extrace
        ...        """.splitlines()]
        >>> [l.strip() for l in gen(source)]
        ['some lines', 'to extrace']

    '''

    if isinstance(source,list):
        lns = source
        source = ""
    else:
        lns = []
        try:
            lns = _read_lines(source)
        except:
            sys.stderr.write("ERROR: {} cannot be opened\n".format(source))
            return
    if '.' not in sys.path:
        sys.path.append('.')
    if fun:
        gen_regex = r'#def gen_'+fun+'(\w*(lns,\*\*kw):)*'
    else:
        gen_regex = r'#def gen(\w*(lns,\*\*kw):)*'
    iblks = list(rindices(gen_regex,lns))
    py3 = '\n'.join([lns[k][lns[i].index('#')+1:] 
            for i,j in in2s(iblks) 
            for k in range(i,j)])
    eval(compile(py3,source+'#gen','exec'),globals())
    if fun:
        gened = list(eval('gen_'+fun+'(lns,**kw)'))
    else:#else eval all gen_ funtions
        gened = []
        for i in iblks[0::2]:
            cd = re.split("#def |:",lns[i])[1]#gen(lns,**kw)
            gened += list(eval(cd))
    if target:
        drn = os.path.dirname(target)
        if drn and not os.path.exists(drn):
            os.makedirs(drn)
        with open(target,'w',encoding='utf-8') as o:
            o.write(''.join(((x or '\n') for x in gened)))
    else:
        return gened

def parsegenfile(
    genpth #path to gen file
    ):
    '''
    Parse the file ``genpth`` which has format ::

      sourcefile | targetfile | suffix | kw paramams or {}

    ``suffix`` refers to ``gen_<suffix>``.

    The yields are used for the |dcx.gen| function.
    '''

    try:
        genfilelns = _read_lines(genpth)
    except:
        sys.stderr.write("ERROR: {} cannot be opened\n".format(genpth))
        return
        
    for ln in genfilelns:
        if ln[0] != '#':
            try:
              f,t,d,a = [x.strip() for x in ln.split('|')]
              kw=eval(a)
              yield f,t,d,kw
            except: pass

def mkdir(ef):
    try:
        os.mkdir(ef)
    except:
        pass

def mktree(
    tree #tree string as list of lines
    ):
    ''' 

    Build a directory tree from a string as returned by the tree tool.

    The level is determined by the identation.

    Leafs:

    - ``/`` or ``\\`` to make a directory leaf

    - ``<<`` to copy file from internet using ``http://`` or locally using ``file:://``

    - use indented lines as file content

    Example::

        >>> tree="""
        ...          a
        ...          ├aa.txt
        ...            this is aa
        ...          └u.txt<<http://docutils.sourceforge.net/docs/user/rst/quickstart.txt
        ...          b
        ...          ├c
        ...          │└d/
        ...          ├e  
        ...          │└f.txt
        ...          └g.txt
        ...            this is g
        ...       """.splitlines()
        >>> #mktree(tree) 

    '''

    for treestart,t in enumerate(tree):
        try:
            ct = re.search(r'[^\s├│└]',t).span()[0]
            break
        except:
            continue
    t1 = [t[ct:] for t in tree[treestart:]]
    entry_re = re.compile(r'^(\w[^ </\\]*)(\s*<<\s*|\s*[\\/]\s*)*(\w.*)*')
    it1 = list(rindices(entry_re,t1))
    lt1 = len(t1)
    it1.append(lt1)
    for c,f in intervals(it1):
        ef,ed,eg = entry_re.match(t1[c]).groups()
        if ef:
            if c<f-1:
                p1 = t1[c+1].find('└')+1
                p2 = t1[c+1].find('├')+1
                ix = (p1>=0 and p1 or p2)-1
                if ix >= 0 and ix <= len(ef):
                    mkdir(ef)
                    old = os.getcwd()
                    os.chdir(ef)
                    mktree(
                      t1[c+1:f]
                      )
                    os.chdir(old)
                else:
                    t0 = t1[c+1:f]
                    ct = re.search(r'[^\s│]',t0[0]).span()[0]
                    tt = [t[ct:]+'\n' for t in t0]
                    with open(ef,'w') as fh:
                        fh.writelines(tt)
            elif eg:
                request.urlretrieve(eg,ef)
            elif ed and (('\\' in ed) or ('/' in ed)):
                mkdir(ef)
            else:
                Path(ef).touch()

def tree(
    path #path of which to create the tree string
    ,with_content=False #use this only if all the files are text
    ,with_files=True #else only directories are listed
    ,with_dot_files=True #also include files starting with .
    ,max_depth=100 #max folder depth to list
    ):
    '''
    Inverse of mktree.
    Like the linux tree tool, but optionally with content of files

    ::

      >>> path='.'
      >>> tree(path,False)
      >>> tree(path,True)

    '''

    subprefix = ['│  ', '   '] 
    entryprefix = ['├─', '└─']
    def _tree(path, prefix):
        for p,ds,fs in os.walk(path):
            #p,ds,fs = path,[],os.listdir()
            lends = len(ds)
            lenfs = len(fs)
            if len(prefix)/3 >= max_depth:
                return
            for i,d in enumerate(sorted(ds)):
                yield prefix + entryprefix[i==lends+lenfs-1] + d
                yield from _tree(os.path.join(p,d),prefix+subprefix[i==lends+lenfs-1])
            del ds[:]
            if with_files:
                for i,f in enumerate(sorted(fs)):
                    if with_dot_files or not f.startswith('.'):
                        yield prefix + entryprefix[i==lenfs-1] + f
                        if with_content:
                            for ln in _read_lines(os.path.join(p,f)):
                                yield prefix + subprefix[1] + ln
    return '\n'.join(_tree(path, ''))


def fldrs(
    scanroot='.' #root path to start scanning for independent doc folders
    ):
    '''
    Yields::

        fldr, (lnktgts,allfiles,alltgts)

    These are used by |dcx.lnksandtags|.
    '''

    odir = os.getcwd()
    os.chdir(scanroot)
    fldr_lnktgts = OrderedDict()
    fldr_allfiles = defaultdict(set) #fldr, files
    fldr_alltgts = defaultdict(set) #all link target ids
    dcns=set([])
    for dcs in fldrincluded('.'): 
        rest = next(adc for adc in dcs if is_rest(adc))
        restpath,restext = os.path.splitext(rest)
        fldr,restname = os.path.split(restpath)
        fldr_allfiles[fldr] |= set(dcs)
        if restext == _stpl:
            reststpl = True
            restname=os.path.splitext(restname)[0]
        else:
            reststpl = False
        dcns.add(restname)
        for doc in dcs:
            if doc==rest and reststpl and os.path.exists(restpath):
                lns = _read_lines(restpath)
                fil = _read_stpl_lines(doc)
                tgts = list(make_tgts(lns,doc,fil))
            elif not doc.endswith('.tpl') and os.path.exists(doc):#%include('x.rst.tpl') were considered in first branch
                lns = _read_lines(doc)
                tgts = list(make_tgts(lns,doc))
            else:
                continue
            lnks = list(links(lns))
            if fldr not in fldr_lnktgts:
                fldr_lnktgts[fldr] = []
            fldr_lnktgts[fldr].append((restname,doc,len(lns),lnks,tgts))
            fldr_alltgts[fldr] |= set([n for ni,n,nn in tgts])
    for fldr,lnktgts in fldr_lnktgts.items():
        allfiles = fldr_allfiles[fldr]
        alltgts = fldr_alltgts[fldr]
        yield fldr, (lnktgts,allfiles,alltgts)
    os.chdir(odir)

doctypes = "sphinx docx pdf".split()

def lnksandtags(
    fldr #folder path
    ,lnktgts  #list of links and targets in a document (restname, doc, lenlns, lnks, tgts)
    ,allfiles #all files in one folder
    ,alltgts  #all targets of the whole folder
    ):
    '''
    Creates links_xxx.rst and .tags files for a folder ``fldr`` in that folder.

    If ``pyfca`` is available also the dependencies file ``_trace.rst`` is created.

    conf.py entries::

      file_id_color={
          "meta":("m","white"),
          "ra":("r","lightblue"),
          "sr":("s","red"),
          "dd":("d","yellow"), 
          "tp":("t","green"),
          "rstdoc":("o","pink")}
      html_extra_path=["_images/_trace.svg"]

    IDs starting with the letter in file_id_color are assumed to be from that file.
    This is used to color an FCA lattice diagram in "_trace.rst".
    The diagram nodes are clickable in HTML.

    For ``_trace.png`` one needs the cairosvg library.

    '''

    _tgtsdoc = [(doctype,[]) for doctype in doctypes]
    tagentries = []
    objects = [] #in FCA sense: set of target tgt with all its links to other targets 
    upcnt = 0
    if (fldr.strip()):
       upcnt = len(fldr.split(os.sep))
    #unknowntgts = []
    def tracelines():
        try:
            confpy = nj(fldr,'conf.py')
            if not os.path.exists(confpy):
                confpy = os.path.normpath(nj(fldr,'..','conf.py'))
            config={}
            with open(confpy,encoding='utf-8') as f:
                eval(compile(f.read(),os.path.abspath(confpy),'exec'),config)
            file_id_color=config['file_id_color']
            def _drawnode(canvas,node,parent,c,r): 
                od = []
                its = {x[0] for x in node.intent}
                for k,(k0,v) in file_id_color.items():
                    if k0 in its:
                        od.append(v)
                odl = len(od)
                for i in range(odl-1,-1,-1):
                    rr = int(r*(i+1)/odl)
                    parent.add(canvas.circle(c,rr,fill=od[i],stroke='black'))
        except:
            _drawnode = None
            file_id_color=None
        fca = pyfca.Lattice(objects,lambda x:x)
        tr = 'tr'
        reflist = lambda x,pfx=tr: ('|'+pfx+('|, |'+pfx).join([str(x)for x in sorted(x)])+'|') if x else ''
        trace = [(".. _`"+tr+"{0}`:\n\n:"+tr+"{0}:\n\n{1}\n\nUp: {2}\n\nDown: {3}\n\n").format(
                n.index, reflist(n.intent,''), reflist(n.up), reflist(n.down))
                for n in fca.nodes]
        tlines = ''.join(trace).splitlines(keepends=True)
        tlines.extend(['.. _`trace`:\n','\n','.. figure:: _images/'+trace_file_name+'.png\n','   :name:\n','\n',
          '   |trace|: `FCA <https://en.wikipedia.org/wiki/Formal_concept_analysis>`__ diagram of dependencies'])
        if file_id_color is not None:
            legend=', '.join([fnm+" "+clr for fnm,(_,clr) in file_id_color.items()])
            tlines.extend([': '+legend,'\n'])
        tlines.append('\n')
        with open(nj(fldr,trace_file_name+'.rst'),'w',encoding='utf-8') as f:
            f.write('.. raw:: html\n\n')
            #needs in conf.py: html_extra_path=["_images/_trace.svg"]
            f.write('    <object data="'+trace_file_name+'.svg" type="image/svg+xml"></object>\n')
            if file_id_color is not None:
                f.write('    <p><a href="https://en.wikipedia.org/wiki/Formal_concept_analysis">FCA</a> diagram of dependencies with clickable nodes: '+legend+'</p>\n\n')
            f.writelines(tlines)
        ld = pyfca.LatticeDiagram(fca,4*297,4*210)
        mkdir(nj(fldr,"_images"))
        tracesvg = os.path.abspath(nj(fldr,"_images",trace_file_name+'.svg'))
        ttgt = lambda : trace_target.endswith('.rest') and os.path.splitext(trace_target)[0] or trace_target
        ld.svg(target=ttgt()+'.html#'+tr,drawnode=_drawnode).saveas(tracesvg)
        try:
            import cairosvg
            pngf = tracesvg.replace('.svg','.png')
            cairosvg.svg2png(url="file:///"+tracesvg, write_to=pngf)
        except Exception as e:
            print(e)
        return tlines
    def add_target(tgt,lnkname,restname,upcnt,fi):
        for doctype,doclns in _tgtsdoc:
            if doctype=='sphinx':
                tgte = ".. |{0}| replace:: :ref:`{1}<{0}>`\n".format(tgt,lnkname)
            elif doctype=='docx':
                tgte = ".. |{0}| replace:: `{1} <{2}#{0}>`_\n".format(tgt,lnkname,restname+'.docx')
            elif doctype=='pdf':
                tgte = ".. |{0}| replace:: `{1} <{2}#{0}>`_\n".format(tgt,lnkname,restname+'.pdf')
            doclns.append(tgte)
        tagentries.append('{0}	{1}	/\.\. _`\?{0}`\?:/;"		line:{2}'.format(tgt,"../"*upcnt+fi[0],fi[1]))
    def add_linksto(i,tgt,iterlnks,ojlnk=None): #all the links away from the block following this tgt to next tgt
        linksto = []
        if ojlnk and ojlnk[0] < i:
            if ojlnk[1] in alltgts:
                linksto.append(ojlnk[1])
            else:
                linksto.append('-'+ojlnk[1])
                #unknowntgts.append(ojlnk[1])
            tgt = ojlnk[2]
            ojlnk = None
        if ojlnk is None:
            for j, lnk in iterlnks:
                if j > i:#links upcnt to this target
                    ojlnk = j,lnk,tgt
                    break
                else:
                    if lnk in alltgts:
                        linksto.append(lnk)
                    else:
                        linksto.append('-'+lnk)
                        #unknowntgts.append(lnk)
        if linksto:
            if ojlnk:
                objects.append(set([x for x in linksto if not x.startswith('-') and not x.startswith('_')]+[tgt]))
            linksto = '.. .. ' + ','.join(linksto) + '\n\n'
            for _,doclns in _tgtsdoc:
                doclns.append(linksto)
        return ojlnk
    orestname = None
    for restname, doc, lenlns, lnks, tgts in lnktgts:
         if restname != orestname:
             orestname = restname
             if verbose:
                 print('    '+restname+'.rest')
         if not is_rest(doc):
             if verbose:
                 print('        '+doc)
         for _,doclns in _tgtsdoc:
             doclns.append('\n.. .. {0}\n\n'.format(doc))
         iterlnks = iter(lnks)
         ojlnk=None
         for (i,fi),tgt,lnkname in tgts:
             if i is not None:
               ojlnk = add_linksto(i,tgt,iterlnks,ojlnk)
               add_target(tgt,lnkname,restname,upcnt,fi)
         ojlnk = add_linksto(lenlns,None,iterlnks,ojlnk)
    if len(objects)>0:
        tlns = tracelines()
        if tlns:
            for (_,fi),tgt,lnkname in make_tgts(tlns,trace_file_name+'.rst') :
                add_target(tgt,lnkname,trace_target,0,fi)
    for doctype,doclns in _tgtsdoc:
        with open(nj(fldr,'_links_%s.rst'%doctype),'w',encoding='utf-8') as f:
            f.write('\n'.join(doclns));
    with open(nj(fldr,'.tags'),'wb') as f:
        f.write('\n'.join(tagentries).encode('utf-8'));


#==============> for building with WAF

try:
    from waflib import TaskGen, Task
    import stpl as bottle

    @lru_cache()
    def _ant_glob_stpl(bldpath,stardotext):
        res = []
        sofar = []
        stplsfirst = bldpath.ant_glob(stardotext+_stpl)
        for x in stplsfirst:
            sofar.append(x.name[:-len(_stpl)])
            res.append(x)
        nonstpls = bldpath.ant_glob(stardotext)
        for x in nonstpls:
            if x.name not in sofar:
                res.append(x)
        return res
    @lru_cache()
    def _pth_nde_parent(foldernode,name):
        existsin = lambda x: os.path.exists(os.path.join(x.abspath(),name))
        _parent = foldernode.parent
        if existsin(_parent):
            pth = '../'+name
            nde = _parent.find_node(name)
        else:
            pth = name
            _parent = foldernode
            if existsin(_parent):
                nde = _parent.find_node(name)
            else:
                nde = _parent.make_node(name)
        return pth,nde,_parent.abspath()
    gensrc={}
    @TaskGen.feature('gen_files')
    @TaskGen.before('process_rule')
    def gen_files(self):
        global gensrc
        gensrc={}
        for f,t,fun,kw in parsegenfile(self.path.make_node('gen').abspath()):
            gensrc[t]=f
            frm = self.path.find_resource(f)
            twd = self.path.make_node(t)
            self.create_task('gentsk',frm,twd,fun=fun,kw=kw)
    class gentsk(Task.Task):
        def run(self):
            frm = self.inputs[0]
            twd = self.outputs[0]
            twd.parent.mkdir()
            gen(frm.abspath(),twd.abspath(),fun=self.fun,**self.kw)
    def get_docs(bld):
        docs = [x.lower() for x in bld.options.docs]
        if not docs:
            docs = [x.lower() for x in bld.env.docs]
        return docs
    @lru_cache()
    def get_files_in_folder(path):
        deps = []
        for rest in _ant_glob_stpl(path,'*.rest'):
            if not rest.name.startswith('index'):
                fles = rstincluded(rest.name,(rest.parent.abspath(),))
                for x in fles:
                    isrst = is_rst(x)
                    if isrst and x.startswith('_links_'):#else cyclic dependency for _links_xxx.rst
                        continue
                    nd = path.find_node(x)
                    if not nd:
                        if isrst and not x.endswith(_stpl):
                            nd = path.find_node(x+_stpl)
                    deps.append(nd)
        depsgensrc = [path.find_node(gensrc[x]) for x in deps if x and x in gensrc] 
        rs = [x for x in deps if x]+depsgensrc
        return (rs,[])
    @lru_cache()
    def get_files_in_doc(path,node):
        srcpath = node.parent.get_src()
        orgd = node.parent.abspath()
        d = srcpath.abspath()
        n = node.name
        nod = None
        if node.is_bld() and not node.name.endswith(_stpl):
            nod = srcpath.find_node(node.name+_stpl)
        if not nod:
            nod = node
        ch = rstincluded(n,(d,orgd),True)
        deps = []
        nodeitself=True
        for x in ch:
            if nodeitself:
                nodeitself = False
                continue
            isrst = is_rst(x)
            if isrst and x.startswith('_links_'):#else cyclic dependency for _links_xxx.rst
                    continue
            nd = srcpath.find_node(x)
            if not nd:
                if isrst and not x.endswith(_stpl):
                    nd = srcpath.find_node(x+_stpl)
            deps.append(nd)
        depsgensrc = [path.find_node(gensrc[x]) for x in deps if x and x in gensrc] 
        rs = [x for x in deps if x]+depsgensrc
        return (rs,[])
    @TaskGen.feature('gen_links')
    @TaskGen.before('process_rule')
    def gen_links(self):
        docs=get_docs(self.bld)
        if docs:
            linksandtags = [self.path.make_node(x) for x in ['_links_'+x+'.rst' for x in doctypes]+['.tags']]
            self.create_task('rstindex',self.path,linksandtags,scan=lambda:get_files_in_folder(self.path))
    class rstindex(Task.Task):
        always_run = True
        def run(self):
            for fldr, (lnktgts,allfiles,alltgts) in fldrs(self.inputs[0].abspath()):
                lnksandtags(fldr,lnktgts,allfiles,alltgts)
    def stpl(tsk,bld):
        bldpath = bld.path.get_bld()
        ps = tsk.inputs[0].abspath()
        pt = tsk.outputs[0].abspath()
        lookup,name=os.path.split(ps)
        env = tsk.env
        env.update(tsk.generator.__dict__)
        #if the .stpl needs a parameter, then this fails, since it is intended to be used as include file only: name it .tpl then
        st=bottle.template(name
                ,template_settings={'esceape_func':lambda x:x}
                ,template_lookup = [lookup,os.path.split(lookup)[0]]
                ,bldpath = bldpath.abspath()
                ,options = bld.options
                ,__file__ = ps.replace('\\','/')
                ,**env
                )
        with open(pt,mode='w',encoding="utf-8",newline="\n") as f:
            f.write(st)
    class Stpl(Task.Task):
        always_run = True
        def run(self):
            stpl(self,self.generator.bld)
    @TaskGen.extension(_stpl)
    def expand_stpl(self,node):#expand into same folder
        nn = node.parent.make_node(node.name[:-len(_stpl)])
        self.create_task('Stpl',node,nn)
        try:
            self.get_hook(nn)(self, nn)
        except:
            pass
    def sphinxcontrib_tikz(tsk):
        from sphinxcontrib import tikz
        from argparse import Namespace
        class Builder:
            def __init__(s):
                s.config = Namespace(**config)
                s.imgpath,s.imgnode,s.outdir = _pth_nde_parent(tikzpth,'_images')
                s.name = 'html'
                try:
                    s.libs = s.config.tikz_tikzlibraries
                    s.libs = s.libs.replace(' ', '').replace('\t', '').strip(', ')
                except AttributeError as e:
                    raise ValueError(str(e).replace('Namespace','conf.py'))
        class SphinxMock:
            def __init__(s):
                s.builder = Builder()
                tikz.builder_inited(s)
        tikzpth = tsk.inputs[0].parent.get_src()
        _,confpy,__ = _pth_nde_parent(tikzpth,'conf.py')
        config={}
        eval(compile(confpy.read(encoding='utf-8'),confpy.abspath(),'exec'),config)
        sphinxmock = SphinxMock()
        tikzfn = tikz.render_tikz(sphinxmock,{'tikz':tsk.inputs[0].read(encoding='utf-8')},sphinxmock.builder.libs)
        os.replace(tikzpth.make_node(tikzfn).abspath(),tsk.outputs[0].abspath())
    class Tikz(Task.Task):
        def run(self):
            sphinxcontrib_tikz(self)
    @TaskGen.extension('.tikz')
    def tikz_to_png(self,node):#into _images or ../_images in source path
        srcfldr = node.parent.get_src()
        _,imgnde,__ = _pth_nde_parent(srcfldr,'_images')
        self.create_task('Tikz',node,imgnde.make_node(node.name[:-5]+'.png'))
    @TaskGen.extension('.rest')
    def gen_docs(self,node):
        docs=get_docs(self.bld)
        linkdeps = [self.path.get_src().find_node(x) for x in ['_links_'+x+'.rst' for x in doctypes]]
        d = get_files_in_doc(self.path,node)
        for dx in d[0]:
            if dx.name.endswith(_stpl):
                target_in_src_folder = dx.get_src().parent.make_node(dx.name[:-len(_stpl)])
                self.create_task('Stpl',dx,target_in_src_folder)
        rstscan = lambda: d
        if node.name != "index.rest":
            if 'docx' in docs or 'defaults' in docs:
                out_node_docx = node.parent.find_or_declare('docx/'+node.name[:-len('.rest')]+'.docx')
                self.create_task('docx', [node]+linkdeps, out_node_docx, scan=rstscan)
            if 'pdf' in docs:
                out_node_pdf = node.parent.find_or_declare('pdf/'+node.name[:-len('.rest')]+'.pdf')
                self.create_task('pdf', [node]+linkdeps, out_node_pdf, scan=rstscan)
        else:
            if 'html' in docs:
                out_node_html = node.parent.get_bld()
                self.create_task('sphinx',[node]+linkdeps,out_node_html,cwd=node.parent.abspath(),scan=rstscan)
    class pdfordocx(Task.Task):
        def run(self):
            frm = self.inputs[0].abspath()
            twd = self.outputs[0].abspath()
            dr = self.inputs[0].parent.get_src()
            refoption,refdoc,cmd,linksdoc = self.refdoc_cmd(twd)
            rd = dr.find_resource(refdoc) or dr.parent.find_resource(refdoc)
            if rd:
                cmd.append(refoption)
                cmd.append(rd.abspath())
            oldp = os.getcwd()
            os.chdir(dr.abspath())
            try:
                with open(frm,'rb') as f:
                    k1 = f.read().replace(b'\n.. include:: _links_sphinx.rst',b'')
                links_docx = dr.find_resource(linksdoc)
                with open(links_docx.abspath(),'rb') as f:
                    k2 = f.read()
                p = subprocess.Popen(cmd, stdin=subprocess.PIPE)
                p.stdin.write(k1)
                p.stdin.write(k2)
                p.stdin.close()    
                p.wait()
            finally:
                os.chdir(oldp)
    class pdf(pdfordocx):
        def refdoc_cmd(self,output):
            pandoc = ['pandoc','--listings','--number-sections', 
                '--pdf-engine','xelatex','-f', 'rst']+ list(chain.from_iterable(zip(['-V']*4,
                ['titlepage','papersize=a4','toc','toc-depth=3','geometry:margin=2.5cm']
                )))+ ['-o', output]
            return '--template','reference.tex', pandoc, '_links_pdf.rst'
    class docx(pdfordocx):
        def refdoc_cmd(self,output):
            pandoc = ['pandoc','-f', 'rst', '-t', 'docx', '-o', output]
            return '--reference-doc','reference.docx', pandoc, '_links_docx.rst'
    class sphinx(Task.Task):
        always_run = True
        def run(self):
            dr = self.inputs[0].parent
            tgt = self.outputs[0].find_or_declare('html').abspath()
            relconfpy,confpy,_ = _pth_nde_parent(dr,'conf.py')
            confdir = os.path.split(relconfpy)[0]
            cwd=self.get_cwd().abspath()
            subprocess.run(['sphinx-build','-Ea', '-b', 'html',dr.abspath(),tgt]+(
                ['-c',confdir] if confdir else []),cwd=cwd)

    def options(opt):
        def docscb(option, opt, value, parser):
            setattr(parser.values, option.dest, value.split(','))
        opt.add_option("--docs", type='string', action="callback", callback= docscb, dest='docs', default=[],
            help="Like html,docx (default) or html,pdf or html,docx,pdf at configure or build (default None)") 

    def configure(cfg):
        cfg.env['docs'] = cfg.options.docs

    def build(bld):
        bld.src2bld = lambda f: bld(features='subst',source=f,target=f,is_copy=True)
        def gen_files():
            bld(features="gen_files")
            bld.add_group()
        bld.gen_files = gen_files
        def gen_links():
            bld(features="gen_links")
            bld.add_group()
        bld.gen_links = gen_links
        bld.sphinxcontrib_tikz = sphinxcontrib_tikz
        bld.stpl = lambda tsk: stpl(tsk,bld) #use like bld(rule=bld.stpl,source='x.h.stpl'), but rule actually not needed
        def build_docs():
            docs=get_docs(bld)
            if docs:
                for tikz in _ant_glob_stpl(bld.path,'*.tikz'):
                    bld(source=tikz)
                    bld.add_group()
                bld(source=_ant_glob_stpl(bld.path,'*.rest'))
        bld.build_docs = build_docs

except:
    pass

#==============< for building with WAF

#this is for mktree(): first line of file content must not be empty!
example_tree = r'''
       src
        ├ dcx.py << file:///__file__
        ├ reference.tex << file:///__tex_ref__
        ├ code
        │   └ some.h
                /*
                #def gen_tst(lns,**kw):
                #  return [l.split('@')[1] for l in rlines('^\s*@',lns)]
                #def gen_tst
                #def gen_tstdoc(lns,**kw):
                #  return ['#) '+l.split('**')[1] for l in rlines('^/\*\*',lns)]
                #def gen_tstdoc

                @//generated from some.h
                @#include <assert.h>
                @#include "some.h"
                @int main()
                @{
                */

                /**Test add1()
                @assert(add1(1)==2);
                */
                int add1(int a)
                {
                  return a+1;
                }

                /**Test add2()
                @assert(add2(1)==3);
                */
                int add2(int a)
                {
                  return a+2;
                }

                /*
                @}
                */
        ├ wscript
            from waflib import Logs
            Logs.colors_lst['BLUE']='\x1b[01;36m'

            top='.'
            out='../build'

            def options(opt):
              opt.load('dcx',tooldir='.')

            def configure(cfg):
              cfg.load('dcx',tooldir='.')
              
            def build(bld):
              #defines bld.gen_files(), bld.gen_links(), bld.build_docs()
              bld.load('dcx',tooldir='.')
              bld.recurse('doc')

        └ doc
           ├ wscript_build
           │    bld.gen_files()
           │    bld.gen_links()
           │    bld.build_docs()
           ├ index.rest
           │  ============
           │  Project Name
           │  ============
           │
           │  .. toctree::
           │     ra.rest
           │     sr.rest
           │     dd.rest
           │     tp.rest
           │
           │  One can also have a 
           │  
           │  - issues.rest for issues
           │  
           │  - pp.rest for the project plan 
           │    (with backlog, epics, stories, tasks) 
           │
           │  .. include:: _trace.rst
           │  
           │  .. include:: _links_sphinx.rst
           │  
           ├ ra.rest
           │  Risk Analysis
           │  =============
           │  
           │  .. _`rz7`:
           │  
           │  :rz7: risk calculations
           │  
           │  Risk calculations are done with python in the ``.stpl`` file.
           │  
           │  .. include:: _links_sphinx.rst
           │  
           ├ sr.rest
           │  Software/System Requirements
           │  ============================
           │
           │  Requirements mostly phrased as tests (see |t9a|). 
           │
           │  .. _`sy7`:
           │
           │  A Requirement Group
           │  -------------------
           │
           │  .. _`s3a`:
           │
           │  :s3a: brief description
           │
           │  Don't count the ID, since the order will change.
           │  The IDs have the first letter of the file and 2 or more random letters of ``[0-9a-z]``.
           │  Use an editor macro to generate IDs.
           │  
           │  If one prefers ordered IDs, one can use templates::
           │  
           │    %id = lambda x=[0]: x.append(x[-1]+1) or "s{:0>2}".format(x[-1])
           │  
           │    .. _`soi`:
           │  
           │    :{{id()}}: auto numbered.
           │  
           │  The disadvantage is that the id will differ between rst and final doc.
           │  When this is needed in an included file use template include: ``%include('x.rst.tpl`)``
           │  See the the ``test/stpl`` folder.
           │
           │  Every ``.rest`` has this line at the end::
           │  
           │     .. include:: _links_sphinx.rst
           │  
           │  .. include:: _links_sphinx.rst
           │  
           ├ dd.rest
           │  Design Description
           │  ==================
           │  
           │  ``dcx.py`` produces its own labeling consistent across DOCX, PDF, HTML.
           │  
           │  .. _`dz7`:
           │  
           │  :dz7: Independent DD IDs
           │  
           │    The relation with RS IDs is m-n. Links like |s3a| can be scattered over more DD entries.  
           │  
           │  .. _`dz3`:
           │  
           │  .. figure:: _images/smpl.png
           │     :name:
           │  
           │     |dz3|: Caption here.
           │  
           │     The usage of ``:name:`` produces: ``WARNING: Duplicate explicit target name: ""``. Ignore.
           │  
           │  Reference via |dz3|.
           │  
           │  .. _`dua`:
           │  
           │  |dua|: Table legend
           │  
           │  .. table::
           │     :name:
           │  
           │     +----+----+
           │     | A  | B  |
           │     +====+====+
           │     | 10 | 11 |
           │     +----+----+
           │  
           │  .. _`dta`:
           │  
           │  |dta|: Table legend
           │  
           │  .. list-table::
           │     :name:
           │     :widths: 20 80
           │     :header-rows: 1
           │  
           │     * - Bit
           │       - Function
           │  
           │     * - 0
           │       - afun
           │  
           │  Reference |dta| does not show ``dta``.
           │  
           │  .. _`dyi`:
           │  
           │  |dyi|: Listing showing struct.
           │  
           │  .. code-block:: cpp
           │     :name:
           │  
           │     struct astruct{
           │        int afield; //afield description 
           │     }
           │  
           │  Reference |dyi| does not show ``dyi``.
           │  
           │  .. _`d9x`:
           │  
           │  .. math:: 
           │     :name:
           │  
           │     V = \frac{K}{r^2}
           │  
           │  Reference |d9x| does not show ``d9x``.
           │  
           │  .. _`d99`:
           │  
           │  :OtherName: Keep names the same all over.
           │  
           │  Here instead of ``d99:`` we use ``:OtherName:``, but now we have two synonyms for the same item.
           │  This is no good. If possible, keep ``d99`` in the source and in the final docs.
           │  
           │  Reference |d99| does not show ``d99``.
           │  
           │  The item target must be in the same file as the item content. The following would not work::
           │  
           │    .. _`dh5`:
           │    
           │    .. include:: somefile.rst   
           │  
           │  .. include:: _links_sphinx.rst
           │  
           ├ tp.rest
           │  Test Plan
           │  =========
           │  
           │  .. _`t9a`:
           │  
           │  Requirement Tests
           │  -----------------
           │
           │  No duplication. Only reference the requirements to be tested.
           │
           │  - |s3a|
           │
           │  Or better: reference the according SR chapter, else changes there would need an update here.
           │
           │  - Test |sy7|
           │
           │  Unit Tests
           │  ----------
           │
           │  Use ``.rst`` for included files and start the file with ``_`` if generated.
           │  
           │  .. include:: _sometst.rst
           │
           │  .. include:: _links_sphinx.rst
           │
           ├ smpl.tikz
               [thick]
               \draw (0,0) grid (3,3);
               \foreach \c in {(0,0), (1,0), (2,0), (2,1), (1,2)}
                   \fill \c + (0.5,0.5) circle (0.42);
           ├ gen
              #from|to|gen_xxx|kwargs
              ../code/some.h | _sometst.rst                | tstdoc | {}
              ../code/some.h | ../../build/code/some_tst.c | tst    | {}
           ├ conf.py
              extensions = ['sphinx.ext.autodoc',
                  'sphinx.ext.todo',
                  'sphinx.ext.mathjax',
                  'sphinx.ext.viewcode',
                  'sphinx.ext.graphviz',
                  ]
              numfig = False
              smartquotes = False
              file_id_color={"ra":("r","lightblue"), "sr":("s","red"), "dd":("d","yellow"), "tp":("t","green")}
              default_role = 'math'
              templates_path = ['_templates']
              source_suffix = '.rest'
              master_doc = 'index'
              project = 'sample'
              author = project+' Project Team'
              copyright = '2017, '+author
              version = '1.0'
              release = '1.0.0'
              language = None
              highlight_language = "none"
              exclude_patterns = []
              pygments_style = 'sphinx'
              todo_include_todos = True
              import sphinx_bootstrap_theme
              html_theme = 'bootstrap'
              html_theme_path = sphinx_bootstrap_theme.get_html_theme_path()
              latex_engine = 'xelatex'
              tikz_transparent = True
              tikz_proc_suite = 'ImageMagick'
              tikz_tikzlibraries = 'arrows,snakes,backgrounds,patterns,matrix,shapes,fit,calc,shadows,plotmarks,intersections'
              tikz_latex_preamble = r"""
              \usepackage{unicode-math}
              \usepackage{tikz}
              \usepackage{caption}
              \captionsetup[figure]{labelformat=empty}
              """
              latex_elements = {
              'preamble':tikz_latex_preamble+r"\usetikzlibrary{""" + tikz_tikzlibraries+ '}'
              }
              latex_documents = [
                  (master_doc, project.replace(' ','')+'.tex',project+' Documentation',author,'manual'),
              ]
           └ Makefile
              SPHINXOPTS    = 
              SPHINXBUILD   = sphinx-build
              SPHINXPROJ    = docxsmpl
              SOURCEDIR     = .
              BUILDDIR      = ../../build/doc
              .PHONY: docx help Makefile docxdir pdfdir index
              docxdir: ${BUILDDIR}/docx
              pdfdir: ${BUILDDIR}/pdf
              MKDIR_P = mkdir -p
              ${BUILDDIR}/docx:
              	${MKDIR_P} ${BUILDDIR}/docx
              ${BUILDDIR}/pdf:
              	${MKDIR_P} ${BUILDDIR}/pdf
              index:
              	python ../dcx.py
              help:
              	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
              	@echo "  docx        to docx"
              	@echo "  pdf         to pdf"
              %: Makefile index
              	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
              docx: docxdir index
              	cat sr.rest _links_docx.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst -t docx -o "$(BUILDDIR)/docx/sr.docx"
              	cat dd.rest _links_docx.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst -t docx -o "$(BUILDDIR)/docx/dd.docx"
              	cat tp.rest _links_docx.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst -t docx -o "$(BUILDDIR)/docx/tp.docx"
              	cat ra.rest _links_docx.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst -t docx -o "$(BUILDDIR)/docx/ra.docx"
              pdf: pdfdir index
              	cat sr.rest _links_pdf.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst --pdf-engine xelatex --number-sections -V papersize=a4 -V toc -V toc-depth=3 -V geometry:margin=2.5cm -o "$(BUILDDIR)/pdf/sr.pdf"
              	cat dd.rest _links_pdf.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst --pdf-engine xelatex --number-sections -V papersize=a4 -V toc -V toc-depth=3 -V geometry:margin=2.5cm -o "$(BUILDDIR)/pdf/dd.pdf"
              	cat tp.rest _links_pdf.rst | sed -e's/^.. include:: _links_sphinx.rst//g'  | pandoc -f rst --pdf-engine xelatex --number-sections -V papersize=a4 -V toc -V toc-depth=3 -V geometry:margin=2.5cm -o "$(BUILDDIR)/pdf/tp.pdf"
              	cat ra.rest _links_pdf.rst | sed -e's/^.. include:: _links_sphinx.rst//g' | pandoc -f rst --pdf-engine xelatex --number-sections -V papersize=a4 -V toc -V toc-depth=3 -V geometry:margin=2.5cm -o "$(BUILDDIR)/pdf/ra.pdf"
       build/'''

def main(**args):
  '''
  This corresponds to the |rstdcx| shell command.
  '''

  import codecs
  import argparse

  if not args:
    parser = argparse.ArgumentParser(description='''Sample RST Documentation for HTML and DOCX.
      Creates |substitution| links and ctags for link targets.
      ''')
    parser.add_argument('--init', dest='root', action='store',
                        help='''create a sample folder structure. 
                        Afterwards run "make html" or "make docx" form "doc" folder.''')
    parser.add_argument('-v','--verbose', action='store_true',
                        help='''Show files recursively included by each rest''')
    args = parser.parse_args().__dict__

  iroot = args['root']
  global verbose
  verbose = args['verbose']
  if iroot:
    thisfile = str(Path(__file__).resolve()).replace('\\','/')
    tex_ref = os.path.normpath(os.path.join(os.path.split(thisfile)[0],'..','reference.tex'))
    tree=[l for l in example_tree.replace(
        '__file__',thisfile).replace('__tex_ref__',tex_ref).splitlines() if l.strip()]
    mkdir(iroot)
    oldd = os.getcwd()
    os.chdir(iroot)
    mktree(tree)
    os.chdir('src')
    subprocess.run("pandoc --print-default-data-file reference.docx > reference.docx",shell=True)
    os.chdir(oldd)
  else:
    #link, gen and tags per folder
    for fldr, (lnktgts,allfiles,alltgts) in fldrs('.'):
        if verbose:
            print(fldr)
        #generate files
        genpth = nj(fldr,'gen')
        if os.path.exists(genpth):
            for f,t,d,kw in parsegenfile(genpth):
                gen(nj(fldr,f),target=nj(fldr,t),fun=d,**kw)
        lnksandtags(fldr,lnktgts,allfiles,alltgts)

if __name__=='__main__':
  main()

