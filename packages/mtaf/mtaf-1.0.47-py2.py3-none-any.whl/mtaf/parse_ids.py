import csv
import re
from user_exception import UserException as Ux
import six


re_id = re.compile('.*,([^,]*:id/[^,]*),[^,]*,(\d+),(\d+),(\d+),(\d+)')


def parse_zpaths(csv_fullpath):
    zpaths = {}
    short_zpaths = {}
    with open(csv_fullpath) as f:
        reader = csv.DictReader(f, quotechar="'")
        for row in reader:
            if row['zpath'] in zpaths:
                raise Ux("Expected zpaths to be unique, found duplicate: %s" % row['zpath'])
            try:
                x1 = int(row['min_x'])
                y1 = int(row['min_y'])
                x2 = int(row['lim_x'])
                y2 = int(row['lim_y'])
                zpaths[row['zpath']] = {
                    'id': row['resource-id'],
                    'geoms': [
                        {"x1": x1, "y1": y1, "x2": x2, "y2": y2}
                    ]
                }
            except ValueError:
                pass
            except TypeError:
                six.print_("TypeError processing %s" % repr(row))

    for zpath in zpaths:
        short_zpath = get_relative_zpath(zpath, zpaths)
        short_zpaths[short_zpath] = zpaths[zpath]
    return short_zpaths


def get_relative_zpath(zpath, zpaths):
    short_zpath = zpath
    zterms = zpath.split('/')
    # - for each full zpath, calculate the minimum "tail" that will uniquely locate the element
    # - do this by incrementing the number of zpath terms in the tail until no other full zpaths match
    # - for this purpose, remove '[1]' enumerators from the zpath strings being evaluated because,
    #   when doing a "find by zpath" via webdriver/appium, #1 in a group of zpaths (designated by '[1]')
    #   will conflict with a similar tail that lacks the '[1]' because it is not part of an enumerated group)
    for count in range(len(zterms)):
        # increase "nterms" until the tail with "nterms" terms only matches the current zpath
        nterms = count + 1
        tail = '/'.join(zpath.split('/')[-1 * nterms:])
        match_count = 0
        for _zpath in zpaths:
            # create a _tail for each _zpath with the current number of terms
            _tail = '/'.join(_zpath.split('/')[-1 * nterms:])
            if ''.join(_tail.split('[1]')) == ''.join(tail.split('[1]')):
                if match_count == 0:
                    # this will happen at least once since "_zpath" iterates through "zpaths",
                    # which contains "zpath"
                    match_count += 1
                else:
                    # if there are multiple matches to the current tail, break the "for _zpaths" loop
                    # (i.e., don't check any more full zpaths for a tail match)
                    break
        else:
            # all zpaths were checked for tail match without finding two matches
            # the current tail will be used, so prepend "//'
            short_zpath = '//' + tail
            #
            break
    return short_zpath


def parse_ids(csv_fullpath):
    ids = {}
    with open(csv_fullpath) as f:
        reader = csv.DictReader(f, quotechar="'")
        for row in reader:
            _id = row['resource-id']
            if _id != '':
                try:
                    x1 = int(row['min_x'])
                    y1 = int(row['min_y'])
                    x2 = int(row['lim_x'])
                    y2 = int(row['lim_y'])
                    if _id in ids:
                        ids[_id].append({"x1": x1, "y1": y1, "x2": x2, "y2": y2})
                    else:
                        ids[_id] = [{"x1": x1, "y1": y1, "x2": x2, "y2": y2}]
                except ValueError:
                    six.print_("ValueError parsing row: %s" % row)
    return ids


def parse_ids_with_zpaths(csv_fullpath):
    ids = parse_ids(csv_fullpath)
    ids_with_zpath = {}
    zpaths = parse_zpaths(csv_fullpath)
    for id in ids:
        matching_zpaths = []
        for zpath in zpaths:
            if zpaths[zpath]['id'] == id:
                matching_zpaths.append(zpath)
        ids_with_zpath[id] = {
            'zpath': matching_zpaths,
            'geoms': ids[id]
        }
    return ids_with_zpath


if __name__ == "__main__":
    default_csv = '/tmp/MtafInspector/inspector.csv'
    import argparse
    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,
                                     description='  parses csv file generated by xml_to_csv.py and prints element' +
                                                 '  position and id info\n')
    parser.add_argument("-z", "--zpath", dest='zpath', action='store_true')
    parser.add_argument("-q", "--quiet", dest='quiet', action='store_true')
    args = parser.parse_args()
    if args.zpath:
        locs = parse_zpaths(default_csv)
    else:
        locs = parse_ids_with_zpaths(default_csv)
    if not args.quiet:
        loc_keys = locs.keys()
        max_len = len(max(loc_keys, key=lambda x: len(x)))
        fmt1 = "%%-%ds%%60s%%s" % max_len
        fmt = "%%-%ds %%s" % max_len
        for loc in sorted(locs):
            if args.zpath:
                six.print_(fmt1 % (loc, locs[loc]['id'], locs[loc]['geoms'][0]))
                for geom in locs[loc]['geoms'][1:]:
                    six.print_(fmt1 % ("", "", geom))
            else:
                for i, zpath in enumerate(locs[loc]['zpath']):
                    if i == 0:
                        six.print_(fmt1 % (loc, locs[loc]['zpath'][i], locs[loc]['geoms'][0]))
                    else:
                        six.print_(fmt1 % ('', locs[loc]['zpath'][i], ''))
                for geom in locs[loc]['geoms'][1:]:
                    six.print_(fmt1 % ("", "", geom))
            # else:
            #     print fmt1 % (loc, "", locs[loc][0])
            #     for geom in locs[loc][1:]:
            #         print fmt1 % ("", "", geom)
